{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Importing the Training dataset\n",
    "people_ID, Region, Designation and Name will not effect the chances of getting infected so they are not treated as independent variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataset = pd.read_excel(\"Train_dataset.xlsx\")\n",
    "X_TrainDataset = trainDataset.iloc[:,:-1]\n",
    "y_TrainDataset = trainDataset.iloc[:,-1].values\n",
    "X_TrainDataset.drop(X_TrainDataset.columns[[0, 1, 3, 4]], axis=1, inplace=True)\n",
    "\n",
    "testDataset = pd.read_excel(\"Test_dataset.xlsx\")\n",
    "\n",
    "#testDataset = pd.read_csv(\"Test_Data_27.csv\")  #FOR PREDICTING ON 27TH MARCH. # FIRST RUN Solution_part2.ipynb FOR CREATING Test_Data_27.csv\n",
    "\n",
    "ids = testDataset['people_ID']\n",
    "X_TestDataset = testDataset.iloc[:,:]\n",
    "X_TestDataset.drop(X_TestDataset.columns[[0, 1, 3, 4]], axis=1, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Encoding the Dataset\n",
    "Encoded Gender, Married, Occupation, Mode Transport, Comorbidity, Pulmonary score and cardiological pressure. Then drop their first column to avoid dummy variable trap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_TrainDatasetencoded = pd.get_dummies(X_TrainDataset, columns= X_TrainDataset.columns[[0, 1, 3, 4, 7, 10, 11]], drop_first=True)\n",
    "X_TestDatasetencoded = pd.get_dummies(X_TestDataset, columns= X_TestDataset.columns[[0, 1, 3, 4, 7, 10, 11]], drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Fixing the missing values\n",
    "For all missing values take mean value of that coloumn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arpit\\lib\\site-packages\\sklearn\\utils\\deprecation.py:66: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "c:\\users\\arpit\\lib\\site-packages\\sklearn\\utils\\deprecation.py:66: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "imputer = Imputer(missing_values = 'NaN', strategy = 'mean', axis = 0)\n",
    "imputer = imputer.fit(X_TrainDatasetencoded)\n",
    "X_TrainDatasetencoded = imputer.transform(X_TrainDatasetencoded)\n",
    "\n",
    "imputer = Imputer(missing_values = 'NaN', strategy = 'mean', axis = 0)\n",
    "imputer = imputer.fit(X_TestDatasetencoded)\n",
    "X_TestDatasetencoded = imputer.transform(X_TestDatasetencoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Backend Elimination\n",
    "Remove all the insignificant independent variables to optimize the model.\n",
    "First append a column made of all 1's to encoded array to act as intercept.\n",
    "Significance Level is set to 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pval of dim removed: 30\n",
      "37 dimensions remaining...\n",
      "pval of dim removed: 14\n",
      "36 dimensions remaining...\n",
      "pval of dim removed: 15\n",
      "35 dimensions remaining...\n",
      "pval of dim removed: 23\n",
      "34 dimensions remaining...\n",
      "pval of dim removed: 25\n",
      "33 dimensions remaining...\n",
      "pval of dim removed: 30\n",
      "32 dimensions remaining...\n",
      "pval of dim removed: 31\n",
      "31 dimensions remaining...\n",
      "pval of dim removed: 30\n",
      "30 dimensions remaining...\n",
      "pval of dim removed: 25\n",
      "29 dimensions remaining...\n",
      "pval of dim removed: 18\n",
      "28 dimensions remaining...\n",
      "pval of dim removed: 18\n",
      "27 dimensions remaining...\n",
      "pval of dim removed: 4\n",
      "26 dimensions remaining...\n",
      "pval of dim removed: 22\n",
      "25 dimensions remaining...\n",
      "pval of dim removed: 11\n",
      "24 dimensions remaining...\n",
      "pval of dim removed: 5\n",
      "23 dimensions remaining...\n",
      "pval of dim removed: 17\n",
      "22 dimensions remaining...\n",
      "pval of dim removed: 8\n",
      "21 dimensions remaining...\n",
      "pval of dim removed: 11\n",
      "20 dimensions remaining...\n",
      "pval of dim removed: 16\n",
      "19 dimensions remaining...\n",
      "pval of dim removed: 15\n",
      "18 dimensions remaining...\n",
      "pval of dim removed: 9\n",
      "17 dimensions remaining...\n",
      "pval of dim removed: 15\n",
      "16 dimensions remaining...\n",
      "pval of dim removed: 14\n",
      "15 dimensions remaining...\n",
      "pval of dim removed: 14\n",
      "14 dimensions remaining...\n",
      "pval of dim removed: 11\n",
      "13 dimensions remaining...\n",
      "pval of dim removed: 2\n",
      "12 dimensions remaining...\n",
      "pval of dim removed: 7\n",
      "11 dimensions remaining...\n",
      "pval of dim removed: 6\n",
      "10 dimensions remaining...\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.285\n",
      "Model:                            OLS   Adj. R-squared:                  0.285\n",
      "Method:                 Least Squares   F-statistic:                     475.2\n",
      "Date:                Mon, 23 Mar 2020   Prob (F-statistic):               0.00\n",
      "Time:                        04:00:45   Log-Likelihood:                -38771.\n",
      "No. Observations:               10714   AIC:                         7.756e+04\n",
      "Df Residuals:                   10704   BIC:                         7.763e+04\n",
      "Df Model:                           9                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         55.9278      0.454    123.148      0.000      55.038      56.818\n",
      "x1             2.2616      0.109     20.819      0.000       2.049       2.474\n",
      "x2             2.1857      0.102     21.396      0.000       1.986       2.386\n",
      "x3             0.1067      0.023      4.539      0.000       0.061       0.153\n",
      "x4             0.0162      0.002      7.425      0.000       0.012       0.020\n",
      "x5             0.0042      0.002      2.642      0.008       0.001       0.007\n",
      "x6          -3.57e-07   1.44e-07     -2.486      0.013   -6.38e-07   -7.55e-08\n",
      "x7           -11.8924      0.216    -55.155      0.000     -12.315     -11.470\n",
      "x8            -1.1836      0.288     -4.107      0.000      -1.748      -0.619\n",
      "x9            -0.5526      0.282     -1.963      0.050      -1.105      -0.001\n",
      "==============================================================================\n",
      "Omnibus:                     1450.355   Durbin-Watson:                   1.982\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            13624.520\n",
      "Skew:                           0.329   Prob(JB):                         0.00\n",
      "Kurtosis:                       8.485   Cond. No.                     7.68e+06\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 7.68e+06. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "X_TrainDatasetencoded = np.append(arr = np.ones((X_TrainDatasetencoded.shape[0],1)).astype(int), values=X_TrainDatasetencoded, axis=1)\n",
    "X_TestDatasetencoded = np.append(arr = np.ones((X_TestDatasetencoded.shape[0],1)).astype(int), values=X_TestDatasetencoded, axis=1)\n",
    "\n",
    "sigLevel = 0.05\n",
    "X_TrainOpt = X_TrainDatasetencoded[:,:]\n",
    "X_TestOpt = X_TestDatasetencoded[:,:]\n",
    "regressor_OLS = sm.OLS(endog=y_TrainDataset, exog = X_TrainOpt).fit()\n",
    "pVals = regressor_OLS.pvalues\n",
    "while pVals[np.argmax(pVals)] > sigLevel:\n",
    "    X_TrainOpt = np.delete(X_TrainOpt, np.argmax(pVals), axis = 1)\n",
    "    X_TestOpt = np.delete(X_TestOpt, np.argmax(pVals), axis = 1)\n",
    "    print(\"pval of dim removed: \" + str(np.argmax(pVals)))\n",
    "    print(str(X_TrainOpt.shape[1]) + \" dimensions remaining...\")\n",
    "    regressor_OLS = sm.OLS(endog = y_TrainDataset, exog = X_TrainOpt).fit()\n",
    "    pVals = regressor_OLS.pvalues\n",
    "\n",
    "print(regressor_OLS.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Splitting the Train dataset into training and  validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_validation , y_train, y_validation = train_test_split(X_TrainOpt, y_TrainDataset, test_size = 0.2 , random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Applying Random Forest Regression to the Train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "                      max_features='auto', max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, n_estimators=300,\n",
       "                      n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                      warm_start=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "regressor = RandomForestRegressor( n_estimators= 300, random_state = 0)\n",
    "regressor.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Calculating Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8982767214752759 0.23302102454083173\n"
     ]
    }
   ],
   "source": [
    "print(regressor.score(X_train,y_train), regressor.score(X_validation, y_validation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Predicting Infaction probability for Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_TestDataset = regressor.predict(X_TestOpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Saving result file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list(zip(ids, y_TestDataset)), columns =['people_ID', 'Infect_Prob']) \n",
    "csvFile = open(\"Part1.csv\", 'a' ,encoding='utf-8')\n",
    "df.to_csv(csvFile, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 446,
   "position": {
    "height": "40px",
    "left": "702.2px",
    "right": "20px",
    "top": "127px",
    "width": "755.6px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
